---
title: "STAT 577 Project"
output: html_notebook
---

# Predicting Sales Using Linear Regression
## A Case Study
### By
## Roshanak Akram
## Nooshin Hamidian
## Parker McCullough
## Varisara Tansakul
### 20 April 2017

```{r}
# Preliminaries
# Data was preprocessed using python with Pandas library, see code/XXX.py
# Load the data from CSV files, Change to absolute path of data
#setwd("/Users/roshanak/Dropbox/UTK/Fall2016/STAT576/HW3/Journey/Journey_CSV")
cust = read.csv(file="/Users/roshanak/Dropbox/UTK/Fall2016/STAT576/Homework/HW3/Journey/Journey_CSV/transaction_data.csv", header=TRUE)

cust_1 <- cust[which(cust$DAY < 31),]

demo = read.csv(file="/Users/roshanak/Dropbox/UTK/Spring 2017/STAT 577/Project/demo_ToCategorical.csv", header=TRUE)

head(cust)
summary(cust)

library(sqldf)
stmt <- "SELECT household_key,DAY,STORE_ID,RETAIL_DISC,TRANS_TIME,WEEK_NO,COUPON_DISC,
COUPON_MATCH_DISC,
SUM(SALES_VALUE) AS TotalValue
FROM cust
GROUP BY household_key"
trans1 <- sqldf(stmt)

DF = merge(demo, trans1, ,by="household_key")
DF$TRANS_TIME_Cat <- cut(DF$TRANS_TIME,
                     breaks=c(56, 1200, 1201, 2354),
                     labels=c("1","2","3"))
write.csv(DF,file="DF.csv")

#####Just Using the prepared data
#DF = read.csv(file="/Users/roshanak/Dropbox/UTK/Spring 2017/STAT 577/Project/DF.csv", header = TRUE)
#DF= DF[,-1]
#plot(DFs,pch=16,cex=.5) 

#directly fit least squares
# Y = as.numeric(DF[,16])
# 
# #Fit linear model using "lm"
# fit = lm(Y~.,data=DF)
# summary(fit)
# residuals = fit$residuals
# 
# #Test for Autocorrelated Errors
# durbinWatsonTest(fit)
# 
# # variance inflation factor for collinearity
# vif(fit)
# sqrt(vif(fit)) > 3  # problem ( or may be even take value to be 2)
# 
# # Non-constant error variance test
# ncvTest(fit)
# 
# set.seed(100)
# train_index = sample(1:nrow(DF),0.5*nrow(DF)) 
# test_data_ols = DF[-train_index,] 
# 
# # fitted models
# fit_ols = lm(TotalValue ~ .,data = DF[train_index,]) 
# 
# # Obtain Predicted values
# train_pred_ols = fit_ols$fitted.values
# test_pred_ols = predict(fit_ols,newdata = test_data_ols) 
# 
# # Compute MSEs
# train_mse_ols = mean((DF[train_index,16]-train_pred_ols)^2)
# test_mse_ols = mean((DF[-train_index,16]-test_pred_ols)^2)
# 
# 
# c(train_mse_ols) # print training errors
# c(test_mse_ols) # print training errors

##Trying different methods:
#prostate = read.csv("prostate.csv")
#colnames(prostate) = c("lcavol","lweight","age","lbph","svi","lcp","gleason","pgg45","lpsa")
#head(prostate)
DF = na.omit(DF)
DF$household_key = as.numeric(DF$household_key)
DF$AGE_DESC = as.numeric(DF$AGE_DESC)
DF$MARITAL_STATUS_CODE = as.numeric(DF$MARITAL_STATUS_CODE)
DF$INCOME_DESC = as.numeric(DF$INCOME_DESC)
DF$HOMEOWNER_DESC = as.numeric(DF$HOMEOWNER_DESC)
DF$HH_COMP_DESC = as.numeric(DF$HH_COMP_DESC)
DF$HOUSEHOLD_SIZE_DESC = as.numeric(DF$HOUSEHOLD_SIZE_DESC)
DF$KID_CATEGORY_DESC = as.numeric(DF$KID_CATEGORY_DESC)
DF$DAY = as.numeric(DF$DAY)
DF$STORE_ID = as.numeric(DF$STORE_ID)
DF$RETAIL_DISC = as.numeric(DF$RETAIL_DISC)
DF$TRANS_TIME = as.numeric(DF$TRANS_TIME)
DF$WEEK_NO = as.numeric(DF$WEEK_NO)
DF$TRANS_TIME_Cat =  as.numeric(DF$TRANS_TIME_Cat)
str(DF) 
M = cor(DF)
library(corrplot)
corrplot(M, method = "circle")

DF = DF[, c(1:9, 16)]
DF_original = DF
Y_original = DF_original$TotalValue

library(DMwR)
DF = DF_original
outlier.scores <-lofactor(DF, k=200)
outlier <- order(outlier.scores, decreasing=T)[1:50]
DF <- DF[-c(outlier),]

write.csv(DF,file="/Users/roshanak/Dropbox/UTK/Spring 2017/STAT 577/Project/DF_wo_outliers.csv")

Y_outlier = DF$TotalValue

plot(Y_original,type="l",col="black")
lines(Y_outlier,col="red")
legend("topleft", c("Original Y","Without Outliers"),lty=c(1,1),col=c("black","red", cex = 0.75))

plot(Y_outlier[1:375],type="l",col="black", main = "Original data vs Test predictions")
lines(pred.test.lm,col="green")
lines(pred.test.bs,col="orange")
lines(pred.test.b,col="red")
lines(pred.test.l,col="yellow")
lines(pred.test.r,col="purple")
lines(pred.test.en,col="blue")
lines(pred.test.pcr,col="pink")
lines(pred.test.pls,col="brown")
legend("topleft",lty=c(1,1,1,1,1,1,1,1),col=c("green","orange","red","yellow","purple","blue","pink","brown", cex = 0.75))


YY = as.numeric(DF[,10]); #YY = YY - mean(YY) # center the response
XX = as.matrix(DF[,-10]); #XX = scale(XX,center=T,scale=T) # center the predictors
n = nrow(XX)
rep = 20
mse.train.lm = mse.train.bs = mse.train.f = mse.train.b = mse.train.l = mse.train.r = mse.train.en = mse.train.pcr = mse.train.pls = rep(0,rep)
mse.test.lm = mse.test.bs = mse.test.f = mse.test.b = mse.test.l = mse.test.r = mse.test.en =
mse.test.pcr = mse.test.pls = rep(0,rep)

ErrLM_train = ErrPercentLM_train = ErrLM_test = ErrPercentLM_test = rep(0,rep)
ErrBS_train = ErrPercentBS_train = ErrBS_test = ErrPercentBS_test = rep(0,rep)
ErrB_train = ErrPercentB_train = ErrB_test = ErrPercentB_test = rep(0,rep)
ErrL_train = ErrPercentL_train = ErrL_test = ErrPercentL_test = rep(0,rep)
ErrR_train = ErrPercentR_train = ErrR_test = ErrPercentR_test = rep(0,rep)
ErrEN_train = ErrPercentEN_train = ErrEN_test = ErrPercentEN_test = rep(0,rep)
ErrPCR_train = ErrPercentPCR_train = ErrPCR_test = ErrPercentPCR_test = rep(0,rep)
ErrPLS_train = ErrPercentPLS_train = ErrPLS_test = ErrPercentPLS_test = rep(0,rep)

# loop
set.seed(1)
for(i in 1:rep)
{
  train_index = sample(1:n,n/2,replace = FALSE)  # randomly select the indices of the training set
  X = XX[train_index,]  # trainining X
  Y = YY[train_index]  # training Y
  X_test = XX[-c(train_index),] # Test X
  Y_test = YY[-c(train_index)] # Test Y
  train_data = data.frame(X,Y)
  test_data = data.frame(X_test,Y_test)
  
  MeanY_train = mean(Y)
  MeanY_test  = mean(Y_test)
  
  # LM
  lm.fit = lm(Y~., data = train_data) #
  pred.train.lm = predict(lm.fit)
  pred.test.lm = predict(lm.fit,newdata = test_data[,-10])
  mse.train.lm[i] = sqrt(sum((Y - pred.train.lm)^2)/length(Y))
  mse.test.lm[i] = sqrt(sum((Y_test - pred.test.lm)^2)/length(Y_test))
  
  MeanLM_train = mean(pred.train.lm)
  MeanLM_test = mean(pred.test.lm)
  ErrLM_train[i] = abs(MeanLM_train - MeanY_train)
  ErrPercentLM_train[i] = 100*abs(MeanLM_train - MeanY_train)/MeanY_train
  ErrLM_test[i] = abs(MeanLM_test - MeanY_test)
  ErrPercentLM_test[i] = 100*abs(MeanLM_test - MeanY_test)/MeanY_test
  
  #Best Subset
  fitbsub = regsubsets(x=X,y=Y,nbest = 1, nvmax = 10)
  rs = summary(fitbsub)
  plot(rs$bic, xlab="Parameter", ylab="BIC",type = 'l')
  bs.fit = lm(Y ~ INCOME_DESC+HH_COMP_DESC+DAY,data=train_data )#!!!!!!!
  pred.train.bs = predict(bs.fit)
  pred.test.bs = predict(bs.fit,newdata = test_data[,c(4,6,9)])#!!!!!!!
  mse.train.bs[i] = sqrt(sum((Y - pred.train.bs)^2)/length(Y))
  mse.test.bs[i] = sqrt(sum((Y_test - pred.test.bs)^2)/length(Y_test))
  
  MeanBS_train = mean(pred.train.bs)
  MeanBS_test = mean(pred.test.bs)
  ErrBS_train[i] = abs(MeanBS_train - MeanY_train)
  ErrPercentBS_train[i] = 100*abs(MeanBS_train - MeanY_train)/MeanY_train
  ErrBS_test[i] = abs(MeanBS_test - MeanY_test)
  ErrPercentBS_test[i] = 100*abs(MeanBS_test - MeanY_test)/MeanY_test
  
  # forward step-wise
  #fitf0 = lm(Y~1,data=train_data) # fit the model with only the intercept
  #fitf = stepAIC(fitf0,lpsa~.,direction="forward",data=prostate,k=log(nrow(prostate)))
  #pred.train.f = predict(fitf)
  #pred.train.f = predict(fitf,newdata = test_data[,-9])
  #mse.train.f[i] = sum(Y - pred.train.f)^2/length(Y)
  #mse.test.f[i] = sum(Y_test - pred.test.f)^2/length(Y_test)
  
  #backward step-wise
  fitb0 = lm(Y~.,data=train_data)
  fitb = stepAIC(fitb0,direction="backward",data=DF,k=log(nrow(DF)),trace=FALSE)
  pred.train.b  = predict(fitb)
  pred.test.b = predict(fitb,newdata = test_data[,-10])
  mse.train.b[i] = sqrt(sum((Y - pred.train.b)^2)/length(Y))
  mse.test.b[i] = sqrt(sum((Y_test - pred.test.b)^2)/length(Y_test))
  
  MeanB_train = mean(pred.train.b)
  MeanB_test = mean(pred.test.b)
  ErrB_train[i] = abs(MeanB_train - MeanY_train)
  ErrPercentB_train[i] = 100*abs(MeanB_train - MeanY_train)/MeanY_train
  ErrB_test[i] = abs(MeanB_test - MeanY_test)
  ErrPercentB_test[i] = 100*abs(MeanB_test - MeanY_test)/MeanY_test
  
  #lasso
  cvfitl = cv.glmnet(x=X,y=Y,family="gaussian",alpha=1,standardize=FALSE)
  pred.train.l = predict(cvfitl, newx = X, s = "lambda.min") 
  pred.test.l = predict(cvfitl, newx = X_test, s = "lambda.min") 
  mse.train.l[i] = sqrt(sum((Y - pred.train.l)^2)/length(Y))
  mse.test.l[i] = sqrt(sum((Y_test - pred.test.l)^2)/length(Y_test))
  
  MeanL_train = mean(pred.train.l)
  MeanL_test = mean(pred.test.l)
  ErrL_train[i] = abs(MeanL_train - MeanY_train)
  ErrPercentL_train[i] = 100*abs(MeanL_train - MeanY_train)/MeanY_train
  ErrL_test[i] = abs(MeanL_test - MeanY_test)
  ErrPercentL_test[i] = 100*abs(MeanL_test - MeanY_test)/MeanY_test
  
  # Ridge
  cvfitr = cv.glmnet(x=X,y=Y,family="gaussian",alpha=0,standardize=FALSE)
  pred.train.r = predict(cvfitr, newx = X, s = "lambda.min") 
  pred.test.r = predict(cvfitr, newx = X_test, s = "lambda.min") 
  mse.train.r[i] = sqrt(sum((Y - pred.train.r)^2)/length(Y))
  mse.test.r[i] = sqrt(sum((Y_test - pred.test.r)^2)/length(Y_test))
  
  MeanR_train = mean(pred.train.r)
  MeanR_test = mean(pred.test.r)
  ErrR_train[i] = abs(MeanR_train - MeanY_train)
  ErrPercentR_train[i] = 100*abs(MeanR_train - MeanY_train)/MeanY_train
  ErrR_test[i] = abs(MeanR_test - MeanY_test)
  ErrPercentR_test[i] = 100*abs(MeanR_test - MeanY_test)/MeanY_test
  
  # E - net
  cvfiten = cv.glmnet(x=X,y=Y,family="gaussian",alpha=0.5,standardize=FALSE)
  pred.train.en = predict(cvfiten, newx = X, s = "lambda.min") 
  pred.test.en = predict(cvfiten, newx = X_test, s = "lambda.min") 
  mse.train.en[i] = sqrt(sum((Y - pred.train.en)^2)/length(Y))
  mse.test.en[i] = sqrt(sum((Y_test - pred.test.en)^2)/length(Y_test))
  
  MeanEN_train = mean(pred.train.en)
  MeanEN_test = mean(pred.test.en)
  ErrEN_train[i] = abs(MeanEN_train - MeanY_train)
  ErrPercentEN_train[i] = 100*abs(MeanEN_train - MeanY_train)/MeanY_train
  ErrEN_test[i] = abs(MeanEN_test - MeanY_test)
  ErrPercentEN_test[i] = 100*abs(MeanEN_test - MeanY_test)/MeanY_test
  
  # PC regression 
  pcr.fit=pcr(Y~X,scale=TRUE,ncomp = 5)
  pred.train.pcr = predict(pcr.fit, ncomp = 5, newdata = X)
  pred.test.pcr = predict(pcr.fit, ncomp = 5, newdata = X_test)
  mse.train.pcr[i] = sqrt(sum((Y - pred.train.pcr)^2)/length(Y))
  mse.test.pcr[i] = sqrt(sum((Y_test - pred.test.pcr)^2)/length(Y_test))
  
  MeanPCR_train = mean(pred.train.pcr)
  MeanPCR_test = mean(pred.test.pcr)
  ErrPCR_train[i] = abs(MeanPCR_train - MeanY_train)
  ErrPercentPCR_train[i] = 100*abs(MeanPCR_train - MeanY_train)/MeanY_train
  ErrPCR_test[i] = abs(MeanPCR_test - MeanY_test)
  ErrPercentPCR_test[i] = 100*abs(MeanPCR_test - MeanY_test)/MeanY_test
  
  # PLS regression
  pls.fit=plsr(Y~X,scale=TRUE,ncomp = 5)
  pred.train.pls = predict(pls.fit, ncomp = 5, newdata = X)
  pred.test.pls = predict(pls.fit, ncomp = 5, newdata = X_test)
  mse.train.pls[i] = sqrt(sum((Y - pred.train.pls)^2)/length(Y))
  mse.test.pls[i] = sqrt(sum((Y_test - pred.test.pls)^2)/length(Y_test))
  
  MeanPLS_train = mean(pred.train.pls)
  MeanPLS_test = mean(pred.test.pls)
  ErrPLS_train[i] = abs(MeanPLS_train - MeanY_train)
  ErrPercentPLS_train[i] = 100*abs(MeanPLS_train - MeanY_train)/MeanY_train
  ErrPLS_test[i] = abs(MeanPLS_test - MeanY_test)
  ErrPercentPLS_test[i] = 100*abs(MeanPLS_test - MeanY_test)/MeanY_test
  
  
}

mse.train = c(mse.train.lm,mse.train.bs, mse.train.b, mse.train.l,mse.train.r,mse.train.en,
                mse.train.pcr,mse.train.pls)
mse.test = c(mse.test.lm, mse.test.bs, mse.test.b, mse.test.l, mse.test.r, mse.test.en, 
             mse.test.pcr, mse.test.pls)
indicator = c(rep("LM",rep),rep("BS",rep),rep("BackWard",rep),rep("Lasso",rep),rep("Ridge",rep),
              rep("ENET",rep),rep("PCR",rep),rep("PLSR",rep))
par(mfrow=c(1,2))
colours <- c("red", "orange", "blue", "yellow", "green", "hotpink", "brown","purple")
boxplot(mse.train~as.factor(indicator),main="Training RMSE",ylab="RMSE", las=2, col=colours)
boxplot(mse.test~as.factor(indicator),main="Test RMSE",ylab="RMSE", las=2, col=colours)

par(mfrow=c(1,1))
plot(Y, type="l", col="black")
lines(pred.train.bs, col="red")
lines(pred.test.bs, col="blue")

Err_train = c(ErrLM_train,ErrBS_train,ErrB_train,ErrL_train,ErrR_train,ErrEN_train,ErrPCR_train,ErrPLS_train)
Err_test = c(ErrLM_test,ErrBS_test,ErrB_test,ErrL_test,ErrR_test,ErrEN_test,ErrPCR_test,ErrPLS_test)
ErrPercent_train = c(ErrPercentLM_train,ErrPercentBS_train,ErrPercentB_train,ErrPercentL_train,ErrPercentR_train,ErrPercentEN_train,ErrPercentPCR_train,ErrPercentPLS_train)
ErrPercent_test = c(ErrPercentLM_test,ErrPercentBS_test,ErrPercentB_test,ErrPercentL_test,ErrPercentR_test,ErrPercentEN_test,ErrPercentPCR_test,ErrPercentPLS_test)
par(mfrow=c(1,2))
colours <- c("red", "orange", "blue", "yellow", "green", "hotpink", "brown","purple")
boxplot(Err_train~as.factor(indicator),main="Training Error",ylab="Error ($)", las=2, col=colours)
boxplot(Err_test~as.factor(indicator),main="Test Error",ylab="Error ($)", las=2, col=colours)

par(mfrow=c(1,2))
colours <- c("red", "orange", "blue", "yellow", "green", "hotpink", "brown","purple")
boxplot(ErrPercent_train~as.factor(indicator),main="Training Error",ylab="Error (%)", las=2, col=colours)
boxplot(ErrPercent_test~as.factor(indicator),main="Test Error",ylab="Error (%)", las=2, col=colours)

#-------------------------------------------------------------------------
# Boosting
#-------------------------------------------------------------------------
errmat = Err = ErrPercent = matrix(0,50,2)

for(i in 1:50)
{
DF.tr = data.frame(Y,DF[train_index,-10])
bs.DF=gbm(Y~.,data=DF.tr,distribution="gaussian",n.trees=5000,interaction.depth=4)
#summary(bs.DF)

yhat.boost=predict(bs.DF,newdata=test_data,n.trees=5000,interaction.depth=4)
yhat.boost.tr=predict(bs.DF, n.trees=5000,interaction.depth=4)
#sqrt(mean((yhat.boost-Y_test)^2)/length(Y_test)) # MSE
#bs.DF=gbm(Y~.,data=DF.tr,distribution="gaussian",n.trees=5000,interaction.depth=4,shrinkage=0.2,verbose=F)
#yhat.boost=predict(bs.DF,newdata=test_data,n.trees=5000)

MeanBoost_train = mean(yhat.boost.tr)
MeanBoost_test = mean(yhat.boost)

bs.tserr = sqrt(sum((yhat.boost-Y_test)^2)/length(Y_test)) # MSE
bs.trerr = sqrt(sum((yhat.boost.tr-Y)^2)/length(Y))
bs.err = c(bs.trerr, bs.tserr)

BS_train_Err = abs(MeanBoost_train - MeanY_train)
BS_train_ErrPercent = 100*abs(MeanBoost_train - MeanY_train)/MeanY_train
BS_test_Err = abs(MeanBoost_test - MeanY_test)
BS_test_ErrPercent = 100*abs(MeanBoost_test - MeanY_test)/MeanY_test

BS_Err = c(BS_train_Err, BS_test_Err)
BS_ErrPercent = c(BS_train_ErrPercent, BS_test_ErrPercent)

errmat[i,] = c(bs.err) 
Err[i,] = c(BS_Err)
ErrPercent[i,] = c(BS_ErrPercent)
}

labels = as.factor(c(rep("BSTr",50),rep("BSTs",50)))
err = c(errmat)
ErrPlot = c(Err)
ErrPercentPlot = c(ErrPercent)
par(mfrow=c(1,3))
boxplot(err~labels,ylab="RMSE Error $", las=2)
boxplot(ErrPlot~labels,ylab="Error $", las=2)
boxplot(ErrPercentPlot~labels,ylab="Error %", las=2)
```


